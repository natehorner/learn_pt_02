{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbNlCNECIgGBh7LLYtYkUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natehorner/learn_pt_02/blob/main/pytorch_multiclassifciation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0L0DI2v4Wa1",
        "outputId": "7aadd528-5183-4784-b74f-5f9041ab8f35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/805.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/805.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EzUGYU0lolPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0500430-9682-48b7-ef93-d555be5ba123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Train Loss: 1.29531 Train Acc: 0.30%, Test Loss: 1.14015 Test Acc: 0.56%\n",
            "Epoch: 200, Train Loss: 0.00292 Train Acc: 1.00%, Test Loss: 0.00291 Test Acc: 1.00%\n",
            "Epoch: 400, Train Loss: 0.00113 Train Acc: 1.00%, Test Loss: 0.00107 Test Acc: 1.00%\n",
            "Epoch: 600, Train Loss: 0.00067 Train Acc: 1.00%, Test Loss: 0.00061 Test Acc: 1.00%\n",
            "Epoch: 800, Train Loss: 0.00047 Train Acc: 1.00%, Test Loss: 0.00042 Test Acc: 1.00%\n",
            "Epoch: 1000, Train Loss: 0.00036 Train Acc: 1.00%, Test Loss: 0.00031 Test Acc: 1.00%\n",
            "Epoch: 1200, Train Loss: 0.00029 Train Acc: 1.00%, Test Loss: 0.00025 Test Acc: 1.00%\n",
            "Epoch: 1400, Train Loss: 0.00024 Train Acc: 1.00%, Test Loss: 0.00020 Test Acc: 1.00%\n",
            "Epoch: 1600, Train Loss: 0.00020 Train Acc: 1.00%, Test Loss: 0.00017 Test Acc: 1.00%\n",
            "Epoch: 1800, Train Loss: 0.00018 Train Acc: 1.00%, Test Loss: 0.00015 Test Acc: 1.00%\n",
            "Epoch: 1999, Train Loss: 0.00016 Train Acc: 1.00%, Test Loss: 0.00013 Test Acc: 1.00%\n"
          ]
        }
      ],
      "source": [
        "#common\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchmetrics import Accuracy\n",
        "SEED_BASE = int(\"BADBEEF\",16)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if(device == \"cpu\"):\n",
        "  torch.manual_seed(SEED_BASE)\n",
        "else:torch.cuda.manual_seed(SEED_BASE)\n",
        "\n",
        "\n",
        "#Generate data\n",
        "import sklearn\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#debug\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#meta statistics - 2 classes needed to plot...\n",
        "NUM_CLASSES = 4\n",
        "NUM_FEATURES = 6\n",
        "EPOCHS = 2000\n",
        "\n",
        "\n",
        "#create data - some of these are ugly with 4 classes, they can be on top of\n",
        "#each other\n",
        "X_blob,y_blob = make_blobs(n_samples = 1000,\n",
        "                           n_features=NUM_FEATURES,\n",
        "                           centers=NUM_CLASSES,\n",
        "                           cluster_std = 1.2, #changing this doesn't change the shape if seed is used\n",
        "                           random_state=SEED_BASE+61) #I like the look of +6's data set\n",
        "\n",
        "#make tensors\n",
        "X_blob = torch.from_numpy(X_blob).type(torch.float)\n",
        "y_blob = torch.from_numpy(y_blob).type(torch.float)\n",
        "\n",
        "#plt.figure(figsize=(10,7))\n",
        "#plt.scatter(X_blob[:,0],X_blob[:,1],c=y_blob,cmap=plt.cm.RdYlBu)\n",
        "\n",
        "X_blob_train,X_blob_test,y_blob_train,y_blob_test = train_test_split(X_blob,\n",
        "    y_blob,test_size = 0.2,random_state=SEED_BASE)\n",
        "\n",
        "#plt.figure(figsize=(10,7))\n",
        "#plt.scatter(X_blob_train[:,0],X_blob_train[:,1],c=y_blob_train,cmap=plt.cm.RdYlBu)\n",
        "#plt.scatter(X_blob_test[:,0],X_blob_test[:,1],c=y_blob_test,cmap=plt.cm.RdYlBu)\n",
        "\n",
        "#X_blob_test.shape\n",
        "#torch.Size([200, 2])\n",
        "#X_blob_train.shape\n",
        "#torch.Size([800, 2])\n",
        "\n",
        "X_blob_train = X_blob_train.to(device)\n",
        "X_blob_test = X_blob_test.to(device)\n",
        "y_blob_train = y_blob_train.to(device)\n",
        "y_blob_test = y_blob_test.to(device)\n",
        "\n",
        "acc_fn = Accuracy(task=\"MULTICLASS\",num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "#create the model\n",
        "class BlobModel(nn.Module):\n",
        "  def __init__(self,input_features,output_features,hidden_units=8):\n",
        "    super().__init__()\n",
        "    self.linear_layer_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=input_features,out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,out_features=output_features)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_layer_stack(x)\n",
        "\n",
        "blob_model = BlobModel(input_features=NUM_FEATURES,output_features=NUM_CLASSES,hidden_units=16).to(device)\n",
        "\n",
        "#loss/criterion/cost function and optimizer function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.SGD(params=blob_model.parameters(),lr = 0.05)\n",
        "\n",
        "#y_pred_raw = blob_model(X_blob_train[:10,:])\n",
        "#y_pred_prb = torch.softmax(y_pred_raw,dim=1)\n",
        "#y_pred_lbl = torch.argmax(y_pred_prb,dim=1)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  blob_model.train()\n",
        "\n",
        "  y_logits = blob_model(X_blob_train)\n",
        "  y_pred_label = torch.argmax(torch.softmax(y_logits,dim=1),dim=1)\n",
        "\n",
        "  loss_trn = loss_fn(y_logits,y_blob_train.long())\n",
        "  train_acc = acc_fn(y_pred_label,y_blob_train)\n",
        "\n",
        "  optim.zero_grad()\n",
        "  loss_trn.backward()\n",
        "  optim.step()\n",
        "  blob_model.eval()\n",
        "\n",
        "  #only test if we print... why would it test if it doesn't go anywhere?\n",
        "  if epoch % 200 == 0 or epoch == EPOCHS-1:\n",
        "    with torch.inference_mode():\n",
        "\n",
        "      y_tst_lgt = blob_model(X_blob_test).squeeze()\n",
        "      y_test_lbl = torch.argmax(torch.softmax(y_tst_lgt,dim=1),dim=1)\n",
        "      loss_tst = loss_fn(y_tst_lgt,y_blob_test.long())\n",
        "\n",
        "      test_acc = acc_fn(y_blob_test,y_test_lbl)\n",
        "\n",
        "      print(f\"Epoch: {epoch}, Train Loss: {loss_trn:.5f} Train Acc: {train_acc:.2f}%, Test Loss: {loss_tst:.5f} Test Acc: {test_acc:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#debugging: plot how its making a decision since its not training/converging\n",
        "#does it need an internal neuron set because 1 internal layer nhot enough?\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "#download helper functions from pytorch repo if its not downloaded\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.pty is already downloaded\")\n",
        "else:\n",
        "  print(\"download helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\",\"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n"
      ],
      "metadata": {
        "id": "f8PMPh410wcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot decision boundary 10:56:05\n",
        "from helper_functions import plot_predictions,plot_decision_boundary\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(blob_model,X_blob_test,y_blob_test)\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(blob_model,X_blob_test,y_blob_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "pxORme1O00Q0",
        "outputId": "55fd6eef-eca8-48c3-ba82-e3ad4c7ad7de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6b5075d81262>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_blob_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_blob_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mplot_decision_boundary\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0my_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_to_pred_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Test for multi-class or binary and adjust logits to prediction labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-5dbb8bb8ba7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mblob_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlobModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10201x2 and 3x16)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}